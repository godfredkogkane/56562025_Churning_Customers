# -*- coding: utf-8 -*-
"""Godfred_Kogkane_ Assignment 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/147pI1JGTPa3Thy4i1Ecftt3zKXaLPh69

# Importing the necessary libraries that will be required.
"""

#importing the necessary libraries required
import pandas as pd
import numpy as np
import seaborn as sns
import tensorflow as tf
import joblib
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from keras.models import Model
from keras.layers import Input, Dense, BatchNormalization
from keras.optimizers import Adam
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import roc_auc_score, accuracy_score
!pip install keras==2.12.0
from keras.wrappers.scikit_learn import KerasClassifier
from google.colab import drive
drive.mount('/content/drive')

"""# Loading to the telecom customer churn dataset"""

# Loading the telecom customer churn dataset
df = pd.read_csv('/content/drive/My Drive/Assignment/datasets_13996_18858_WA_Fn-UseC_-Telco-Customer-Churn.csv')

"""# This is to view the telecom churn dataset"""

df

"""# Exploring the telecom churn dataset for better understanding."""

# Exploring the dataset
print(df.dtypes)
print(df.head())
print(df.info())
print(df.describe())

"""# Checking to see if there are null values in the dataset. And since there are no missing values in the various coloumns, there is no need drop any column with null values"""

#Checking for the sum missing values
df.isnull().sum()

"""# Dropping the customerID columm as it only uniquely identifies the different customers and is not relevant for the analysis"""

#Dropping the customerID column as it is not relevant for the analysis
df.drop('customerID', axis=1, inplace=True)

"""#Total charge column should be a float but it is showing as object.
#So I have to convert it to float.
"""

#Converting TotalCharges column which is an object to numeric.
# errors = 'coerceâ€™ means, if invalid parsing occur then set NaN
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

"""# Checking to see the data types"""

df.dtypes

"""# Checking to see if there are missing values"""

#Checking for missing values
df.isnull().sum()

"""# Filling null values in TotalCharges with the mean value"""

#Replace the missing values in TotalCharges with the mean value
df['TotalCharges'].fillna(df['TotalCharges'].mean(), inplace=True)

"""# Making analysis of the numeric columns with barchart"""

numeric_columns = df.select_dtypes(include=["int64", "float64"]).columns

for col in numeric_columns:
    if col != 'Churn':
        plt.figure(figsize=(8, 5))
        ax = sns.barplot(x='Churn', y=col, data=df, estimator='mean')
        plt.title(f'{col} vs Churn')
        plt.xlabel('Churn')
        plt.ylabel(col)

        # Labeling the bars
        for k in ax.containers:
            ax.bar_label(
                k, fontsize=10, label_type="center", backgroundcolor="w", fmt="%.2f"
            )

        plt.show()

"""# Interpretation of the barchart
**Senior Citizen:**

Approximately 0.13 average number of customers who are citizens will not churn and 0.25 will churn. This indicates that customers who are senior citizens are more likely to churn than those who are not senior citizens.

**Tenure Months:**

For customers who have not churned, the average tenure is approximately 37.57 months. And for customers who have churned, the average tenure is  lower, at around 17.98 months indicating that customers who have stayed longer with the company are less likely to churn, as suggested by the lower average tenure for churned customers.

**Monthly Charges:**

For customers who have not churned, the average monthly charges are approximately 61.27 dollars and customers who have churned, the average monthly charges are slightly higher, around 74.44 dollars indicating that customers who have churned tend to have slightly higher monthly charges on average.

**Total Charges:**

For customers who have not churned, the average total charges are approximately 2,554.77 dollars and customers who have churned, the average total charges are lower, around 1,531.80 dollars suggesting that customers who have accumulated higher total charges are more likely to continue their subscription and not churn.

# Making analysis of the non-numeric columns with barchart
"""

#Selecting columns with non-numeric
categorical_columns = df.select_dtypes(include=["object"]).columns

#A for loop to plot each categorical column against target (Churn).
for col in categorical_columns:
    plt.figure(figsize=(10, 6))
    ax = sns.countplot(x=col, hue='Churn', data=df)

    # Labeling the bars
    for k in ax.containers:
        ax.bar_label(
            k, fontsize=10, label_type="edge", color="black", fmt="%d"
        )

    plt.title(f'{col} Distribution by Churn')
    plt.show()

"""# In the above barcharts for the non-numeric columns, I studied the Telco Customer Churn dataset to understand the customer churn behavior. I analyzed various categorical variables in relation to the "Churn Label," which indicates whether a customer has churned ("Yes") or not ("No").

# Applying label encoding to non-numeric columns
"""

#Encoding the non-numeric variables
encoder = LabelEncoder()
for col in df.columns:
  if df[col].dtype == 'object':
    df[col] = encoder.fit_transform(df[col])

df.head()

"""#Checking the correlation between the features and the target"""

#Checking the correlation between the features and the target
plt.figure(figsize=(15,10))
sns.heatmap(df.corr(), cmap="RdYlBu", annot=True, fmt=".1f")
plt.show()

"""#Using a threshold of 0.02 to filter out the features that have a low correlation"""

#Using a threshold of 0.02 to filter out the features that have a low correlation
threshold = 0.02
corr = df.corr()
corr_target = abs(corr['Churn'])
relevant_features = corr_target[corr_target > threshold].index
print(relevant_features)

#Spliting the data into train and test sets
X = df[relevant_features].drop('Churn', axis=1)
y = df['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,random_state=42)

#Scaling the data using standard scaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Defining the input layer
inputs = Input(shape=(X_train_scaled.shape[1],))

# Defining the hidden layers
hidden1 = Dense(64, activation='relu')(inputs)
hidden2 = Dense(32, activation='relu')(hidden1)

# Defining the output layer
outputs = Dense(1, activation='sigmoid')(hidden2)

# Creating the model
model = Model(inputs=inputs, outputs=outputs)

# Compiling the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Training the model
model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))

# Evaluating the model before GridSearchCV
y_pred_before = model.predict(X_test_scaled)
accuracy_before = accuracy_score(y_test, y_pred_before.round())
auc_score_before = roc_auc_score(y_test, y_pred_before)

print("Evaluation before GridSearchCV:")
print(f"Accuracy: {accuracy_before}")
print(f"AUC Score: {auc_score_before}")

# Function to create the MLP model
def create_model(hidden1_units=64, hidden2_units=32,learning_rate=0.001):
    inputs = Input(shape=(X_train_scaled.shape[1],))
    hidden1 = Dense(hidden1_units, activation='relu')(inputs)
    hidden2 = Dense(hidden2_units, activation='relu')(hidden1)
    outputs = Dense(1, activation='sigmoid')(hidden2)

    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Creating a KerasClassifier with the model and necessary parameters
model = KerasClassifier(build_fn=create_model, epochs=10,batch_size=32, verbose=0)

# Defining the hyperparameters grid
param_grid = {
    'hidden1_units': [32, 64, 128],
    'hidden2_units': [16, 32, 64],
    'learning_rate': [0.001, 0.01, 0.1]


}

# Using GridSearchCV to search for the best combination of hyperparameters
grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)
grid_result = grid.fit(X_train_scaled, y_train)

# Summarizing results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

# Getting the best model
best_model = grid_result.best_estimator_

# Evaluating the best model on the test set
y_pred_after = best_model.predict(X_test_scaled)
accuracy_after = accuracy_score(y_test, y_pred_after.round())
auc_score_after = roc_auc_score(y_test, y_pred_after)

print("\nEvaluation after GridSearchCV:")
print(f"Accuracy: {accuracy_after}")
print(f"AUC Score: {auc_score_after}")

# Saving the trained model
best_model.model.save('best_model.h5')

# Saving the scaler
joblib.dump(scaler, 'scaler.pkl')